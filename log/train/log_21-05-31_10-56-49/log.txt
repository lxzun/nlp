description: E128-H768-M24-O32-L12-pretrain
num_epochs: 2000
batch_size: 28
step_batch: 500
eval_batch_size: 256
lr: 0.0002
seed: 42
drop_rate: 0.0
embedding_size: 128
hidden_size: 768
m: 24
out_dim: 32
k: 3
n_layer: 12
max_seq_length: 512
task: pretrain
save_vocab: True
pretrained_vocab_path: 
pretrained_vocab: False
save_model: True
pretrained_model_path: 
pretrained_model: False
use_cuda: cuda
multi_gpu: True
Real used device: cuda

---- dataset info ----

* train data *
- num : 8003752

* eval data *
- num : 10017
----------------------



----------------------- 1 epoch start! -----------------------
epoch:  1/2000	|	batch: 500/285849	|	loss: 3.72002
epoch:  1/2000	|	batch: 1000/285849	|	loss: 1.25530
epoch:  1/2000	|	batch: 1500/285849	|	loss: 0.97028
epoch:  1/2000	|	batch: 2000/285849	|	loss: 0.90437
epoch:  1/2000	|	batch: 2500/285849	|	loss: 0.85629
epoch:  1/2000	|	batch: 3000/285849	|	loss: 0.82535
epoch:  1/2000	|	batch: 3500/285849	|	loss: 0.80653
epoch:  1/2000	|	batch: 4000/285849	|	loss: 0.78548
epoch:  1/2000	|	batch: 4500/285849	|	loss: 0.76719
epoch:  1/2000	|	batch: 5000/285849	|	loss: 0.75617
 >> epoch:  1	|	total_batch: 5000	|	eval_loss: 0.74611551
epoch:  1/2000	|	batch: 5500/285849	|	loss: 0.74155
epoch:  1/2000	|	batch: 6000/285849	|	loss: 0.72859
epoch:  1/2000	|	batch: 6500/285849	|	loss: 0.71959
epoch:  1/2000	|	batch: 7000/285849	|	loss: 0.70804
epoch:  1/2000	|	batch: 7500/285849	|	loss: 0.69821
epoch:  1/2000	|	batch: 8000/285849	|	loss: 0.69472
epoch:  1/2000	|	batch: 8500/285849	|	loss: 0.68884
